{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95841ee7",
   "metadata": {},
   "source": [
    "#### Getting started With Langchain And Open AI\n",
    "\n",
    "In this quickstart we'll see how to:\n",
    "\n",
    "- Get setup with LangChain, LangSmith and LangServe\n",
    "- Use the most basic and common components of LangChain: prompt templates, models, and output parsers.\n",
    "- Build a simple application with LangChain\n",
    "- Trace your application with LangSmith\n",
    "- Serve your application with LangServe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7df0685e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY']=os.getenv(\"OPENAI_API_KEY\")\n",
    "## Langsmith Tracking\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=os.getenv(\"LANGCHAIN_PROJECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a18195a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x10e099d10>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x10e09a490>, root_client=<openai.OpenAI object at 0x10e099f90>, root_async_client=<openai.AsyncOpenAI object at 0x10e09a350>, model_name='gpt-4o', model_kwargs={}, openai_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm=ChatOpenAI(model=\"gpt-4o\")\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86519e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "message=\"What is generative ai\"\n",
    "result = llm.invoke(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c377eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Generative AI refers to a class of artificial intelligence systems that are designed to generate new content, including text, images, audio, and video. These systems utilize algorithms and models, particularly deep learning models, to produce outputs that resemble the data they were trained on. Here are some key aspects of generative AI:\\n\\n1. **Machine Learning Models**: Generative AI typically uses complex models such as Generative Adversarial Networks (GANs), Variational Autoencoders (VAEs), and Transformer-based models to learn from existing data and generate new instances that maintain the statistical properties of the training set.\\n\\n2. **Applications**: It has a wide range of applications including the creation of art and design, music composition, text generation (like chatbots and content creation), drug discovery, and even generating synthetic data for training other AI systems.\\n\\n3. **Creative Outputs**: Generative AI is often used to create art and media content, for instance, AI-generated paintings, deepfake videos, and music tracks. These outputs can be used for entertainment or practical purposes like advertising.\\n\\n4. **Text Generation**: In natural language processing, models like GPT (Generative Pre-training Transformer) are capable of generating coherent and contextually relevant text, facilitating applications such as conversational agents, automated writing, and translation.\\n\\n5. **Data Augmentation**: In fields like medical imaging or autonomous driving, generative AI is used to create synthetic data to augment training datasets, improving the performance of other AI systems.\\n\\n6. **Challenges**: While generative AI is powerful, it presents challenges including ethical concerns (e.g., deepfakes, misinformation), biases in the generated content reflective of training data biases, and the need for massive computational resources.\\n\\nGenerative AI continues to be an evolving field with significant impact across various industries, pushing the boundaries of what machines can autonomously create.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 378, 'prompt_tokens': 12, 'total_tokens': 390, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_07871e2ad8', 'id': 'chatcmpl-BnUsC4DMsRGCUiVm2ZGWvYwt6hj1E', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--6a9e4c77-70ad-4f73-aaa3-e5d6673c3e78-0' usage_metadata={'input_tokens': 12, 'output_tokens': 378, 'total_tokens': 390, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0dd72e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer. Provide me answers based on the questions'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ChatPromptTemplate\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are an expert AI Engineer. Provide me answers based on the questions\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ]\n",
    "\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8065a2d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Langchain is a framework designed to facilitate the creation of applications that use large language models (LLMs). It provides a suite of tools and abstractions to help developers efficiently build complex language model-driven applications. The framework focuses on several core capabilities, including:\\n\\n1. **Prompt Management**: Langchain offers tools for prompt construction and management, allowing developers to create, test, and modify prompts that interact with LLMs.\\n\\n2. **Chain Compositions**: It enables the combination of multiple language model calls into chains, where the output of one model can serve as the input to another. This is useful for creating more sophisticated workflows and processing pipelines.\\n\\n3. **Memory and State**: Langchain supports stateful interactions with LLMs, keeping track of conversation history or session data to provide contextually aware responses, which is essential for applications like chatbots.\\n\\n4. **Integration with External Tools and Data**: The framework can integrate with APIs, databases, and other data sources to augment the capabilities of LLMs, allowing them to pull in external information as needed.\\n\\n5. **Deployment and Scalability**: Langchain provides guidance and utilities for deploying LLM-driven applications, ensuring they can scale and be managed effectively in production environments.\\n\\nThese features make Langchain a powerful tool for developers aiming to build applications in areas such as conversational AI, automated content creation, information retrieval, and more. Its modular structure emphasizes seamless integration and rapid development cycles.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 293, 'prompt_tokens': 33, 'total_tokens': 326, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_07871e2ad8', 'id': 'chatcmpl-BnV0ai5FQtUjF75OL3pYpBsGdwy74', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--982834d7-8864-4745-807c-ecfbea480aa9-0' usage_metadata={'input_tokens': 33, 'output_tokens': 293, 'total_tokens': 326, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "## chain (it goes to prompt then add prompt to llm)\n",
    "chain=prompt|llm\n",
    "\n",
    "response=chain.invoke({\"input\":\"Can you tell me about Langchain?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9005917d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5eca241a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain is an open-source framework designed to facilitate the development of applications using large language models (LLMs). It provides a set of foundational components and abstractions that help developers build complex applications with LLMs more efficiently. LangChain is particularly focused on applications involving:\n",
      "\n",
      "1. **Language Model Interactions**: Simplifying the process of connecting with and using LLMs, whether they are hosted locally or accessed via APIs from providers like OpenAI and Hugging Face.\n",
      "\n",
      "2. **Data Augmented Generation**: Enabling models to utilize external data sources to augment their responses. This includes integrating with document stores, APIs, and other data repositories to provide more contextually rich outputs.\n",
      "\n",
      "3. **Chaining**: Creating sequences of calls to language models and other utilities (e.g., external APIs) to accomplish complex tasks.\n",
      "\n",
      "4. **Tool Usage**: Allowing models to interact with tools and perform actions based on their responses, enhancing interactivity and functionality of applications.\n",
      "\n",
      "5. **Memory**: Incorporating state or \"memory\" into language model interactions to enable more coherent and contextually aware dialogues over multiple interactions.\n",
      "\n",
      "6. **Integration with External Systems**: Providing connectors and utils for working with different databases, cloud platforms, and data sources to integrate language model outputs into broader system architectures.\n",
      "\n",
      "LangChain is often used for building applications like chatbots, intelligent agents, and various AI-driven applications that require nuanced procedural logic and interaction patterns with language models. Its modularity and extensibility make it a popular choice for AI engineers and developers looking to leverage the power of LLMs in bespoke applications.\n"
     ]
    }
   ],
   "source": [
    "#output parsers (stroutput Parser)\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser=StrOutputParser()\n",
    "chain=prompt|llm|output_parser\n",
    "\n",
    "response=chain.invoke({\"input\":\"Can you tell me about LangChain?\"})\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
